{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "746220b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3edc4564",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device=mps\n",
      "Jupyter=True, MatPlotLib.isinteractive()=False\n",
      "Unique ID: 2chlTVytQ2O4vAE_xdQFPA\n",
      "PlotVideoMaker: Hyper-Training, auto-save=True\n",
      "middle-C=261.63 Hz\n",
      "PlotVideoMaker: STFT_Video, auto-save=True\n",
      "Using sample rate=44100 Hz, FFT=2048 buckets, hop=1024 samples, duration=1.9 sec = 83 time steps\n",
      "Max frequency=22050 Hz --> freq_buckets=1025\n",
      "STFT file already created: {stft_file}\n",
      "1 sample = 1,025 x 83 = 85,075\n"
     ]
    }
   ],
   "source": [
    "from HyperParameterTuning import *\n",
    "\n",
    "\n",
    "# from MakeSTFTs import *\n",
    "# from Train import *\n",
    "# from AudioUtils import *\n",
    "\n",
    "# Load a demo sample, convert to STFT and back and play the sound.\n",
    "#demo_stft(\"Samples/Piano C4 Major 13.wav\", 2048, 2048*3//4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0542eb5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read all available samples and convert to STFTs\n",
    "# This is performed automatically in the back-ground, but you can force it manually here with plots of the rejected audio files.\n",
    "# make_STFTs(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ff999e2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Find out the best hyper-parameters to train this model (typically needs to run overnight)\n",
    "#model = \"StepWiseMLP\" # or \"RNNAutoEncoder\" and RNN_VAE_Incremental\", or \"StepWiseMLP\" and \"MLPVAE_Incremental\"\n",
    "\n",
    "\n",
    "#model = \"RNNAutoEncoder\"\n",
    "#model = \"RNN_VAE\"\n",
    "#model = \"RNN_VAE_Incremental\"\n",
    "\n",
    "#model = \"StepWiseMLP\"\n",
    "#model = \"MLP_VAE\"\n",
    "model = \"MLPVAE_Incremental\"\n",
    "\n",
    "#model = \"RNN_F&T\"\n",
    "\n",
    "#model = \"STFT_VAE\"\n",
    "\n",
    "# First optimise the hyper-parameters for this model\n",
    "#optimise_hyper_parameters(model)\n",
    "\n",
    "# Then train using the best hyper-parameters\n",
    "#train_best_params(model)\n",
    "\n",
    "\n",
    "# Alternatively, refine the training for the best set of hyper-parameters we've found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f31a5095",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Models/MLP_VAE.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Test and Generate new samples\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mGenerate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 4\u001b[0m use_model(model)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Print some pretty pictures of the samples and their encodings\u001b[39;00m\n\u001b[1;32m      7\u001b[0m demo_encodings()\n",
      "File \u001b[0;32m~/Coding/SampleGen/Generate.py:353\u001b[0m, in \u001b[0;36muse_model\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21muse_model\u001b[39m(model):\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28;01mglobal\u001b[39;00m g\n\u001b[0;32m--> 353\u001b[0m     g \u001b[38;5;241m=\u001b[39m Sample_Generator(model)\n",
      "File \u001b[0;32m~/Coding/SampleGen/Generate.py:39\u001b[0m, in \u001b[0;36mSample_Generator.__init__\u001b[0;34m(self, model_name)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_name):\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28msuper\u001b[39m(Sample_Generator, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_data(model_name)\n",
      "File \u001b[0;32m~/Coding/SampleGen/Generate.py:44\u001b[0m, in \u001b[0;36mSample_Generator.load_data\u001b[0;34m(self, model_name)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_name):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name \u001b[38;5;241m=\u001b[39m model_name\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m load_saved_model(model_name)\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstfts, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_names \u001b[38;5;241m=\u001b[39m load_STFTs()\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategories \u001b[38;5;241m=\u001b[39m infer_sample_categories(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_names)\n",
      "File \u001b[0;32m~/Coding/SampleGen/MakeModels.py:233\u001b[0m, in \u001b[0;36mload_saved_model\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_saved_model\u001b[39m(model_name):\n\u001b[0;32m--> 233\u001b[0m     model_type, params, file_name \u001b[38;5;241m=\u001b[39m get_best_configuration_for_model(model_name)\n\u001b[1;32m    234\u001b[0m     model_params \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;241m2\u001b[39m:] \u001b[38;5;66;03m# remove the optimiser configuration\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     max_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1e99\u001b[39m \u001b[38;5;66;03m# ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/Coding/SampleGen/MakeModels.py:223\u001b[0m, in \u001b[0;36mget_best_configuration_for_model\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_best_configuration_for_model\u001b[39m(model_name):\n\u001b[1;32m    222\u001b[0m     file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModels/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m model_name\n\u001b[0;32m--> 223\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m    224\u001b[0m         first_line \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mreadline()\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m    225\u001b[0m         params \u001b[38;5;241m=\u001b[39m ast\u001b[38;5;241m.\u001b[39mliteral_eval(first_line)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Models/MLP_VAE.txt'"
     ]
    }
   ],
   "source": [
    "# Test and Generate new samples\n",
    "from Generate import *\n",
    "\n",
    "use_model(model)\n",
    "\n",
    "# Print some pretty pictures of the samples and their encodings\n",
    "demo_encodings()\n",
    "\n",
    "# Test the accuracy of the model: lists all samples by decreasing accuracy\n",
    "test_all()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5a2ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
